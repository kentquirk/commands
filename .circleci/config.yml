version: 2.1
aws_defaults: &aws_defaults
  AWS_DEFAULT_REGION: us-east-1
  ECR_ENDPOINT: 578681496768.dkr.ecr.us-east-1.amazonaws.com

commands:
  notify:
    description: "Notifies the team with a message"
    parameters:
      msg:
        type: string
    steps:
      - run:
          name: send message
          command: |
              # this is necessary to get the environment variables to interpolate properly
              echo "{\"text\":\"<< parameters.msg >>\"}" >parms.txt
              curl -X POST -H 'Content-type: application/json' --data @parms.txt https://hooks.slack.com/services/$SLACK_KEY

  notify_error:
    description: "Notifies the team with a message only when an error occurs"
    parameters:
      msg:
        type: string
    steps:
      - run:
          name: send error message
          command: |
              echo "{\"text\":\"<< parameters.msg >>\"}" >parms.txt
              curl -X POST -H 'Content-type: application/json' --data @parms.txt https://hooks.slack.com/services/$SLACK_KEY
          when: on_fail

  mark_honeycomb:
    description: "Places a marker in the specified honeycomb dataset"
    parameters:
      msg:
        type: string
      dataset:
        type: string
    steps:
      - run:
          name: create marker
          command: |
            echo "{\"message\":\"<< parameters.msg >>\", \"type\":\"deploy\"}" >parms.txt
            cat parms.txt   #just to be sure
            curl -X POST -H "X-Honeycomb-Team: $HONEYCOMB_KEY" -d @parms.txt https://api.honeycomb.io/1/markers/<< parameters.dataset >>

  save_image:
    description: "Saves a docker image to the cache"
    parameters:
      img_name:
        type: string
      key:
        type: string
    steps:
      # bring back a cache if one already exists
      - restore_cache:
          key: << parameters.key >>
      - run:
          name: save docker image to cache
          command: |
            # ensure cache directory
            [ -d /opt/docker-cache ] || mkdir -p /opt/docker-cache
            #
            docker save -o "/opt/docker-cache/<< parameters.img_name >>.tar" "<< parameters.img_name >>"
      # saves this path with this cache key
      - save_cache:
          key: << parameters.key >>
          paths:
            - /opt/docker-cache

  setup:
    description: "These steps should be run before any real ci/cd actions"
    steps:
      # add an ssh key granted with this circleci's settings for this repo
      - add_ssh_keys:
          fingerprints:
            - "7d:f1:8e:9e:99:9a:26:e2:4d:0c:66:f3:d4:74:10:e7"
      - setup_remote_docker:
          docker_layer_caching: false
      - run:
          name: AWS ECR Login
          command: eval $(aws ecr get-login --no-include-email --region ${AWS_DEFAULT_REGION})

      - run:
          name: Checkout code
          command: |
            if [ -z "$CIRCLE_BRANCH" ] # if CIRCLE_BRANCH is not set, check out CIRCLE_TAG
            then
              echo "CIRCLE_TAG = $CIRCLE_TAG"
              git clone $CIRCLE_REPOSITORY_URL -b $CIRCLE_TAG /commands
            else # use CIRCLE_BRANCH
              echo "CIRCLE_BRANCH = $CIRCLE_BRANCH"
              git clone $CIRCLE_REPOSITORY_URL -b $CIRCLE_BRANCH /commands
            fi

            # add the circle image's known_hosts file to the known_hosts used inside the images
            cp /root/.ssh/known_hosts /commands/deploy/known_hosts

            # install github machine user key
            # This needs to be here. Otherwise git will cowardly refuse to clone into an non-empty directory.
            echo -e "$machine_user_key" > /commands/machine_user_key

      - run:
          name: get git information
          command: |
            cd /commands
            echo 'export VERSION=$(git describe --long --tags --match="v*")' >> $BASH_ENV
            echo 'export SHA=$(git rev-parse --short $CIRCLE_SHA1)' >> $BASH_ENV
            echo 'export CI_USER=$CIRCLE_USERNAME' >> $BASH_ENV
            echo 'export CI_URL=$CIRCLE_BUILD_URL' >> $BASH_ENV

  setup_ecs_and_identities:
    description: |
      Downloads ecs, configures it and downloads node identities.
      This should be run before any deploy steps.
    steps:
      - run:
          name: download and configure ecs-cli
          command: |
            # download ecs cli
            curl -o /usr/local/bin/ecs-cli https://s3.amazonaws.com/amazon-ecs-cli/ecs-cli-linux-amd64-latest && \
            chmod +x /usr/local/bin/ecs-cli

            # configure ecs
            ecs-cli configure  profile --access-key "$AWS_ACCESS_KEY_ID" --secret-key "$AWS_SECRET_ACCESS_KEY" --profile-name default
            ecs-cli configure --cluster "$CLUSTER_NAME" --region "$AWS_DEFAULT_REGION" --config-name "$CLUSTER_NAME"
      - run:
          name: Download node identities
          command: |
            S3_NODE_ID_ARCHIVE="node-identities-${NETWORK_NAME}.tgz"
            AWS_ACCESS_KEY_ID=$AWS_DEPLOY_SECRETS_ID \
            AWS_SECRET_ACCESS_KEY=$AWS_DEPLOY_SECRETS_KEY \
              aws s3 cp s3://ndau-deploy-secrets/$S3_NODE_ID_ARCHIVE ./$S3_NODE_ID_ARCHIVE
            mkdir -p /root/node-identities
            tar xvf $S3_NODE_ID_ARCHIVE -C /root/node-identities

  deploy-net:
    description: Deploy using ECS
    steps:
      - setup
      - setup_ecs_and_identities
      - mark_honeycomb:
          dataset: $HONEYCOMB_DATASET
          msg: Start deploy for build $CIRCLE_BUILD_NUM
      - ecs_deploy
      - notify:
          msg: Deploy complete; nodes for $NETWORK_NAME are now starting up.

  ecs_deploy:
    description: Deploy using ECS
    steps:
      - run:
          name: deploy
          command: |

            # get bash environment variables from previous steps
            source $BASH_ENV

            # make a persistent peers string with all the static ips
            PEERS=""
            for IP in $STATIC_IPS; do
              PEERS+=($(echo $PERSISTENT_PEERS | sed "s/_IP_/$IP/g"))
            done
            PERSISTENT_PEERS=$(IFS=,; echo "${PEERS[*]}") # join array with ","

            for i in $( seq 0 9 ); do # automatically deploy up to 10 nodes
              echo "Attempting node: $i"
              if [ -f  "/root/node-identities/node-identity-$i.tgz" ]; then
                echo "Found node identity at: "/root/node-identities/node-identity-$i.tgz""
                /commands/docker/bin/deploy-node.sh $i $NETWORK_NAME /root/node-identities
              fi # no else break in case some nodes are updated and others are not
            done


workflows:
  version: 2
  master-build:
    jobs:
      - build-deps:
          filters:
            branches:
              only: /^master$/
      - test:
          filters:
            branches:
              only: /^master$/
          requires:
            - build-deps
      - build:
          filters:
            branches:
              only: /^master$/
          requires:
            - build-deps
      - push:
          requires:
            - test
            - build
          filters:
            branches:
              only: /^master$/
      - deploy-devnet:
          requires:
            - push
          filters:
            branches:
              only: /^master$/
      - integration:
          requires:
            - deploy-devnet
          filters:
            branches:
              only: /^master$/
  tagged-build:
    jobs:
      - build-deps:
          filters:  # required since `push` has tag filters AND requires `test, build`
            tags:
              ignore: /.*-testnet$|.*-mainnet$/ # only run job for these tags
            branches:
              ignore: /^master$/
      - test:
          filters:  # required since `push` has tag filters AND requires `test, build`
            tags:
              ignore: /.*-testnet$|.*-mainnet$/ # only run job for these tags
            branches:
              ignore: /^master$/
          requires:
            - build-deps
      - build:
          filters:  # required since `push` has tag filters AND requires `test-build`
            tags:
              ignore: /.*-testnet$|.*-mainnet$/ # only run job for these tags
            branches:
              ignore: /^master$/
          requires:
            - build-deps
      - push:
          requires:
            - test
            - build
          filters:  # required since `deploy` has tag filters AND requires `push`
            tags:
              only: /.*-push$|.*-deploy$/
            branches:
              ignore: /.*/
      - deploy-devnet:
          requires:
            - push
          filters:
            tags:
              only: /.*-deploy$/
      - deploy-testnet:
          filters:
            tags:
              only: /.*-testnet$/
            branches:
              ignore: /.*/
      - deploy-mainnet:
          filters:
            tags:
              only: /.*-mainnet$/
            branches:
              ignore: /.*/
      - integration:
          requires:
            - deploy-devnet
          filters:
            tags:
              only: /.*-deploy$/

general_config: &general_config
    working_directory: /commands
    docker:
        - image: 578681496768.dkr.ecr.us-east-1.amazonaws.com/circle-ci:0.0.9
    environment:
        shell: /bin/bash
        <<: *aws_defaults
        NDAUHOME: /root/.ndau
        NETWORK_NAME: "devnet" # used for snapshots
        PORT_OFFSET: 0
        PERSISTENT_PEERS: 43cbcf797b4b45823a66d47c4708ee2b4ed378e5@_IP_:30200,fda05e40bd038e175e099fbc55be2e5ef11cd101@_IP_:30201,8dbb62f28d939acc82b68441a0fa301d9fb25f44@_IP_:30202,47bfda03779baa808fe6e4f937b6ff5629088add@_IP_:30203,ea99ac3a4e1a3989bfe537ff2aae083aac9287c6@_IP_:30204 # _IP_ gets s/_IP_/real_ip/g 'd
        STATIC_IPS: 50.17.109.111 54.196.108.229
        CLUSTER_NAME: sc-node-cluster
        SNAPSHOT_URL: https://s3.amazonaws.com/ndau-snapshots/snapshot-testnet-47.tgz

testnet_config: &testnet_config
    working_directory: /commands
    docker:
        - image: 578681496768.dkr.ecr.us-east-1.amazonaws.com/circle-ci:0.0.9
    environment:
        shell: /bin/bash
        <<: *aws_defaults
        NETWORK_NAME: "testnet" # used for snapshots
        PORT_OFFSET: 50 # this gets added to for 30x00y where y is the node number
        PERSISTENT_PEERS: 43cbcf797b4b45823a66d47c4708ee2b4ed378e5@_IP_:31200,fda05e40bd038e175e099fbc55be2e5ef11cd101@_IP_:31201,8dbb62f28d939acc82b68441a0fa301d9fb25f44@_IP_:31202,47bfda03779baa808fe6e4f937b6ff5629088add@_IP_:31203,ea99ac3a4e1a3989bfe537ff2aae083aac9287c6@_IP_:31204 # _IP_ gets s/_IP_/real_ip/g 'd
        STATIC_IPS: 50.17.109.111 54.196.108.229
        CLUSTER_NAME: sc-node=cluster
        SNAPSHOT_URL: https://s3.amazonaws.com/ndau-snapshots/snapshot-testnet-47.tgz

mainnet_config: &mainnet_config
    working_directory: /commands
    docker:
        - image: 578681496768.dkr.ecr.us-east-1.amazonaws.com/circle-ci:0.0.9
    environment:
        shell: /bin/bash
        <<: *aws_defaults
        # nodes will be accessible from their release name combined with a number
        # and the subdomain of the ELB. (e.g. node-0.main.ndau.tech)
        S3_DEPLOY_ARCHIVE: mainnet.tgz
        HONEYCOMB_DATASET: "mainnet"
        NETWORK_NAME: "mainnet" # used for snapshots

jobs:
  build-deps:
    <<: *general_config
    steps:
      - setup
      - run:
          name: build-deps
          command: |
            # build deps image
            docker build -t deps -f /commands/deploy/deps.docker /commands/
      - save_image:
          img_name: deps:latest
          key: "{{ .Revision }}-deps"

  test:
    <<: *general_config
    steps:
      - setup
      - restore_cache:
          key: "{{ .Revision }}-deps"
      - run:
          name: Test
          command: |
            # load previously cached containers
            find /opt/docker-cache -name "*.tar" -exec docker load -i {} \;

            # this runs a test script within the deps image
            docker run --rm \
                -e CI=true \
                deps \
                /bin/sh /root/test.sh

  build:
    <<: *general_config
    steps:
      - setup
      - restore_cache:
          key: "{{ .Revision }}-deps"
      - run:
          name: Build
          command: |
            # load previously cached containers
            find /opt/docker-cache -name "*.tar" -exec docker load -i {} \;

            # this runs a build script within the deps image
            container_id=$(docker create \
                -e CI=true \
                deps \
                /bin/sh /root/build.sh)
            docker start $container_id -a
            container_id=$(docker ps -alq 2>&1)
            docker commit "$container_id" deps-built:latest
      - save_image:
          img_name: deps-built:latest
          key: "{{ .Revision }}-built"

  push:
    <<: *general_config
    steps:
      - setup
      - run:
          name: build the single container image
          command: |
            # TODO let buildimage.sh use the already fetched vendor dir

            # reload saved environment variables
            source $BASH_ENV
            # build single container node image
            ./docker/bin/buildimage.sh
            # retag built image
            docker tag ndauimage 578681496768.dkr.ecr.us-east-1.amazonaws.com/sc-node:$SHA
            # push the image to ECR
            docker push 578681496768.dkr.ecr.us-east-1.amazonaws.com/sc-node:$SHA


  deploy-devnet:
    <<: *general_config
    steps:
      - deploy-net
  deploy-testnet:
    <<: *testnet_config
    steps:
      - deploy-net
  deploy-mainnet:
    <<: *mainnet_config
    steps:
      - deploy-net

  integration:
    <<: *general_config
    steps:
      - setup
      - restore_cache:
          key: "{{ .Revision }}-built"
      - run:
          name: Integration tests
          command: |
            # load previously cached containers
            find /opt/docker-cache -name "*.tar" -exec docker load -i {} \;

            # ensure go path location
            export GOPATH=/go
            mkdir -p $GOPATH/bin
            ndev_dir=$GOPATH/src/github.com/oneiro-ndev
            mkdir -p $ndev_dir
            cd $ndev_dir

            # install dep
            curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

            # install sed?
            apk add sed

            # clone integration tests and ndev dep repos
            git clone git@github.com:oneiro-ndev/integration-tests.git
            ( cd integration-tests && echo "integration-tests repo at $(git rev-parse --short HEAD)" )

            # copy the commands repo and build the ndau tool
            docker run -d --entrypoint /bin/sh deps-build -c 'sleep 60'
            container_id=$(docker ps -alq) # get the last container id
            docker cp $container_id:/go/src/github.com/oneiro-ndev/commands/ndau $ndev_dir/

            # write ndautool from bucket to a file.
            mkdir -p $NDAUHOME/ndau
            AWS_ACCESS_KEY_ID=$AWS_DEPLOY_SECRETS_ID \
            AWS_SECRET_ACCESS_KEY=$AWS_DEPLOY_SECRETS_KEY \
              aws s3 cp s3://ndau-deploy-secrets/$NETWORK_NAME-ndautool.toml $NDAUHOME/ndau/ndautool.toml

            cd integration-tests

            # sync pipenv
            pipenv sync

            # run tests
            NODE_ADDRESS=https://api.ndau.tech \
            NODE_0_RPC=30100 \
            NODE_1_RPC=30101 \
              pipenv run pytest -v --net=devnet --ndauapi=https://api.ndau.tech:30300
